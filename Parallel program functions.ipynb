{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(channel_name):\n",
    "    path = 'G:/EEG Project/Hut lab data/30_sec_epochs/data_raw/'\n",
    "    channel= channel_name\n",
    "    start = time.time()\n",
    "    print('\\n channel: ', channel)\n",
    "    csv_files = glob.glob(path + '*'+channel+'.csv')\n",
    "    score_files = glob.glob(path + '*txt.csv')\n",
    "    \n",
    "    cwt_spectral(csv_files, score_files, channel)\n",
    "    AR_coeff(csv_files, score_files, channel)\n",
    "    temporal(csv_files, score_files, channel)\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = (end - start)/60\n",
    "    print(\"Time to complete: %.2f\" % elapsed, \"mins\")\n",
    "    \n",
    "    \n",
    "def cwt_spectral(csv_files, score_files, channel):\n",
    "    for csv, txt in zip(csv_files, score_files):\n",
    "        name_feature = 'cwt_spectral'\n",
    "        cohl_feature = []\n",
    "        df = pd.read_csv(csv, index_col=0)\n",
    "        df.fillna(0, inplace=True)\n",
    "        tf = pd.read_csv(txt, index_col=0)['Score']\n",
    "        size = int(df.size/len(df))\n",
    "\n",
    "        for i in range(size):\n",
    "            np.seterr(all='ignore')\n",
    "            epoch = np.asarray(df.iloc[:, i])\n",
    "            epoch = epoch[~np.isnan(epoch)]\n",
    "\n",
    "            fs = 128\n",
    "            dt = 1/fs\n",
    "            wave, scales, freqs, coi, fft, fftfreqs = pycwt.wavelet.cwt(epoch, dt)   #, dj, s0, J, mother\n",
    "            cohl = np.abs(wave)\n",
    "            cohl = cohl[::-1]\n",
    "            cohl_flat= cohl.flatten()\n",
    "            splits = [318720, 360960, 395520, 445440]\n",
    "            cwt_spectral = np.split(cohl_flat, splits)\n",
    "\n",
    "            cohl_m = []\n",
    "            cohl_mcr = []\n",
    "            cohl_p = []\n",
    "            cohl_c = []\n",
    "            cohl_f = []\n",
    "            cohl_v = []\n",
    "            cohl_r = []\n",
    "\n",
    "            for s in range(5):\n",
    "                cohl_m.append(np.mean(cwt_spectral[s]))\n",
    "                cohl_mcr.append((np.nonzero(np.diff(cwt_spectral[s] > np.mean(cwt_spectral[s])))[0]).size)\n",
    "                cohl_p.append(np.trapz(cwt_spectral[s]))\n",
    "                cohl_c.append(np.sum(cwt_spectral[s]*len(cwt_spectral[s]))/np.sum(cwt_spectral[s]))\n",
    "                cohl_f.append(scp.stats.mstats.gmean(cwt_spectral[s])/np.mean(cwt_spectral[s]))\n",
    "                cohl_v.append(np.var(cwt_spectral[s]))\n",
    "                cohl_r.append(0.95*np.sum(cwt_spectral[s]))\n",
    "\n",
    "            cohl_feature.append([cohl_m[0], cohl_mcr[0], cohl_p[0], cohl_c[0], cohl_f[0], cohl_v[0], cohl_r[0],\n",
    "                                cohl_m[1], cohl_mcr[1], cohl_p[1], cohl_c[1], cohl_f[1], cohl_v[1], cohl_r[1], \n",
    "                                cohl_m[2], cohl_mcr[2], cohl_p[2], cohl_c[2], cohl_f[2], cohl_v[2], cohl_r[2],\n",
    "                                cohl_m[3], cohl_mcr[3], cohl_p[3], cohl_c[3], cohl_f[3], cohl_v[3], cohl_r[3], \n",
    "                                cohl_m[4], cohl_mcr[4], cohl_p[4], cohl_c[4], cohl_f[4], cohl_v[4], cohl_r[4]])\n",
    "            sys.stdout.write(\"\\r%d%% epochs processed\" % i)\n",
    "\n",
    "        new_df = pd.DataFrame(cohl_feature)                               \n",
    "        new_df.columns = ['Dm', 'Dmcr', 'Dp', 'Dc', 'Df' ,'Dv', 'Dr', \n",
    "                         'Tm', 'Tmcr', 'Tp', 'Tc', 'Tf' ,'Tv', 'Tr',\n",
    "                         'Am', 'Amcr', 'Ap', 'Ac', 'Af' ,'Av', 'Ar', \n",
    "                         'Bm', 'Bmcr', 'Bp', 'Bc', 'Bf' ,'Bv', 'Br',\n",
    "                         'Gm', 'Gmcr', 'Gp', 'Gc', 'Gf' ,'Gv', 'Gr']\n",
    "\n",
    "        big_df = pd.concat([new_df, tf], axis=1)\n",
    "        big_df = big_df[~np.isnan(big_df['Score'])]\n",
    "        big_df = big_df[big_df.Score < 7]\n",
    "        big_df = big_df[~np.isnan(big_df['Gr'])]\n",
    "        toPrint = csv.split('raw\\\\', 1)[1]\n",
    "        toPrint = toPrint.split('.edf', 1)[0]\n",
    "        big_df.to_csv('G:/EEG Project/Hut lab data/30_sec_epochs/cwt_spectral features/'+channel+'/'+toPrint+'_'+name_feature+'.csv')\n",
    "\n",
    "        \n",
    "def AR_coeff(csv_files, score_files, channel):\n",
    "    for csv, txt in zip(csv_files, score_files):\n",
    "        name_feature = 'AR_coeff'\n",
    "        AR_coeff = []\n",
    "        df = pd.read_csv(csv, index_col=0)\n",
    "        df.fillna(0, inplace=True)\n",
    "        tf = pd.read_csv(txt, index_col=0)['Score']\n",
    "        size = int(df.size/len(df))\n",
    "\n",
    "        for i in range(size):\n",
    "            np.seterr(all='ignore')\n",
    "            epoch = np.asarray(df.iloc[:, i])\n",
    "            epoch = epoch[~np.isnan(epoch)]\n",
    "            order_AR = 7\n",
    "            AR, var, k = aryule(epoch, order_AR)\n",
    "            AR_coeff.append(AR)            \n",
    "            \n",
    "            \n",
    "        new_df = pd.DataFrame(AR_coeff)                               \n",
    "        new_df.columns = ['AR_1','AR_2','AR_3','AR_4','AR_5','AR_6','AR_7']\n",
    "        big_df = pd.concat([new_df, tf], axis=1)\n",
    "        big_df = big_df[~np.isnan(big_df['Score'])]\n",
    "        big_df = big_df[big_df.Score < 7]\n",
    "        big_df = big_df[~np.isnan(big_df['AR_7'])]\n",
    "        print('\\n Writing feature set to .csv file...')\n",
    "        toPrint = csv.split('raw\\\\', 1)[1]\n",
    "        toPrint = toPrint.split('.edf', 1)[0]\n",
    "        big_df.to_csv('G:/EEG Project/Hut lab data/30_sec_epochs/AR features/'+channel+'/'+toPrint+'_'+name_feature+'.csv')\n",
    "   \n",
    "def temporal(csv_files, score_files, channel):\n",
    "    for csv, txt in zip(csv_files, score_files):\n",
    "        name_feature = 't_features'\n",
    "        t_features = []\n",
    "        df = pd.read_csv(csv, index_col=0)\n",
    "        df.fillna(0, inplace=True)\n",
    "        tf = pd.read_csv(txt, index_col=0)['Score']\n",
    "        size = int(df.size/len(df))\n",
    "\n",
    "        for i in range(size):\n",
    "            np.seterr(all='ignore')\n",
    "            epoch = np.asarray(df.iloc[:, i])\n",
    "            epoch = epoch[~np.isnan(epoch)]\n",
    "            \n",
    "            mean = np.mean(epoch)\n",
    "            std = np.std(epoch)\n",
    "            minimum = np.amin(epoch)\n",
    "            maximum = np.amax(epoch)\n",
    "            ZCR = (np.nonzero(np.diff(epoch > 0))[0]).size\n",
    "            first_deriv = np.diff(epoch)\n",
    "            second_deriv = np.diff(epoch,2)\n",
    "\n",
    "            var_zero = np.mean(epoch ** 2)\n",
    "            var_d1 = np.mean(first_deriv ** 2)\n",
    "            var_d2 = np.mean(second_deriv ** 2)\n",
    "\n",
    "            activity = var_zero\n",
    "            morbidity = np.sqrt(var_d1 / var_zero)\n",
    "            complexity = np.sqrt(var_d2 / var_d1) / morbidity        \n",
    "            t_features.append([mean, std, minimum, maximum, ZCR, morbidity, complexity])\n",
    "            \n",
    "        new_df = pd.DataFrame(t_features)                               \n",
    "        new_df.columns = ['mean', 'std', 'min', 'max', 'ZCR', 'H_mobility', 'H_complexity']\n",
    "        big_df = pd.concat([new_df, tf], axis=1)\n",
    "        big_df = big_df[~np.isnan(big_df['Score'])]\n",
    "        big_df = big_df[big_df.Score < 7]\n",
    "        big_df = big_df[~np.isnan(big_df['ZCR'])]\n",
    "        print('\\n Writing feature set to .csv file...')\n",
    "        toPrint = csv.split('raw\\\\', 1)[1]\n",
    "        toPrint = toPrint.split('.edf', 1)[0]\n",
    "        big_df.to_csv('G:/EEG Project/Hut lab data/30_sec_epochs/AR features/'+channel+'/'+toPrint+'_'+name_feature+'.csv')\n",
    "   \n",
    "\n",
    "def non_linear():\n",
    "    '''\n",
    "    define the non-linear functins here as and then we can run the whole damn thing as one piece of code parallely\n",
    "    '''\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
