{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting feature extraction of .csv files...\n",
      "\n",
      " processing file 1\n",
      "1297% epochs processed\n",
      " processing file 2\n",
      "1638% epochs processed\n",
      " processing file 3\n",
      "1103% epochs processed\n",
      " processing file 4\n",
      "1420% epochs processed\n",
      " processing file 5\n",
      "1301% epochs processed\n",
      " processing file 6\n",
      "1533% epochs processed\n",
      " processing file 7\n",
      "1097% epochs processed\n",
      " processing file 8\n",
      "1388% epochs processed\n",
      " processing file 9\n",
      "1251% epochs processed\n",
      " processing file 10\n",
      "1638% epochs processed\n",
      " processing file 11\n",
      "1326% epochs processed\n",
      " processing file 12\n",
      "1638% epochs processed\n",
      " processing file 13\n",
      "1109% epochs processed\n",
      " processing file 14\n",
      "1121% epochs processed\n",
      " processing file 15\n",
      "1211% epochs processed\n",
      " processing file 16\n",
      "1210% epochs processed\n",
      " processing file 17\n",
      "1638% epochs processed\n",
      " processing file 18\n",
      "1139% epochs processed\n",
      " processing file 19\n",
      "1559% epochs processed\n",
      " processing file 20\n",
      "1319% epochs processed\n",
      " processing file 21\n",
      "1619% epochs processed\n",
      " processing file 22\n",
      "1319% epochs processed\n",
      " processing file 23\n",
      "1203% epochs processed\n",
      " processing file 24\n",
      "1225% epochs processed\n",
      " processing file 25\n",
      "1293% epochs processed\n",
      " processing file 26\n",
      "1302% epochs processed\n",
      " processing file 27\n",
      "1342% epochs processed\n",
      " processing file 28\n",
      "1325% epochs processed\n",
      " processing file 29\n",
      "1256% epochs processed\n",
      " processing file 30\n",
      "1236% epochs processed\n",
      " processing file 31\n",
      "1638% epochs processed\n",
      " processing file 32\n",
      "1319% epochs processed\n",
      " processing file 33\n",
      "1259% epochs processed\n",
      " processing file 34\n",
      "1366% epochs processed\n",
      " processing file 35\n",
      "1638% epochs processed\n",
      " processing file 36\n",
      "1321% epochs processed\n",
      " processing file 37\n",
      "1528% epochs processed\n",
      " processing file 38\n",
      "1382% epochs processed\n",
      " processing file 39\n",
      "1638% epochs processed\n",
      " processing file 40\n",
      "1367% epochs processed\n",
      " Number of epochs processed: 54552\n",
      "\n",
      " Writing feature set to .csv file...\n",
      "\n",
      " Completed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy.stats as scp\n",
    "import sys\n",
    "path = 'CSV_epoch_data/'\n",
    "\n",
    "kurtosis = []\n",
    "name_feature = 'kurtosis'\n",
    "\n",
    "print('\\n Starting feature extraction of .csv files...')\n",
    "nr_of_epochs = []\n",
    "for idx, filename in enumerate(glob.glob(os.path.join(path, '*.csv'))):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    print('\\n processing file '+str(idx+1))\n",
    "    n = 3840\n",
    "    size = math.ceil((df).size/n)    \n",
    "#     print(df.iloc[:, 1297])\n",
    "    for i in range(size):\n",
    "        sys.stdout.flush()\n",
    "        epoch = np.asarray(df.iloc[:, i])\n",
    "        epoch = epoch[~np.isnan(epoch)]\n",
    "        kurtosis.append(scp.kurtosis(epoch))\n",
    "        sys.stdout.write(\"\\r%d%% epochs processed\" % i)\n",
    "\n",
    "print('\\n Number of epochs processed:', len(kurtosis))\n",
    "feature_csv = pd.DataFrame(kurtosis)\n",
    "feature_csv.columns = [name_feature]\n",
    "print('\\n Writing feature set to .csv file...')\n",
    "feature_csv.to_csv('features/'+name_feature+'.csv')\n",
    "print('\\n Completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful features\n",
    "\n",
    "### Zero-crossing Rate\n",
    "        ZCR.append((np.nonzero(np.diff(epoch > 0))[0]).size)\n",
    "\n",
    "### Hjorth activity                \n",
    "        H_activity.append(np.var(epoch, axis=0))\n",
    "### Hjorth mobility                \n",
    "        H_mobility.append(np.divide(\n",
    "                                    np.std(np.diff(epoch, axis=0)),\n",
    "                                    np.std(epoch, axis=0)))\n",
    "### Hjorth complexity                \n",
    "        mobility = np.divide(np.std(np.diff(epoch, axis=0)),\n",
    "                                    np.std(epoch, axis=0))\n",
    "        H_complexity.append(np.divide(np.divide(\n",
    "                                    np.std(np.diff(np.diff(epoch, axis=0), axis=0), axis=0),\n",
    "                                    np.std(np.diff(epoch, axis=0), axis=0)),\n",
    "                                    mobility))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path = 'features/'\n",
    "# data = []\n",
    "# for idx, filename in enumerate(glob.glob(os.path.join(path, '*.csv'))):\n",
    "#     df = pd.read_csv(filename, index_col=0)\n",
    "#     data.append(df)\n",
    "# # print(data)\n",
    "# bigframe = pd.concat(data, axis=1) #314dont want pandas to try an align row indexes\n",
    "# bigframe.to_csv(\"features/combined_features.csv\")\n",
    "# bigframe.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# import time\n",
    "\n",
    "# features = pd.read_csv('features/combined_features.csv',index_col=0)\n",
    "# features = features[~np.isnan(features['scores'])]\n",
    "# features = features[features.scores < 6]\n",
    "# features.head()\n",
    "\n",
    "# X = features[['H_activity', 'H_complexity', 'H_mobility', 'kurtosis', 'mean', 'skewness', 'ZCR']]\n",
    "# y = features['scores']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# start = time.time()\n",
    "\n",
    "# clf = RandomForestClassifier()\n",
    "# clf.fit(X_train, y_train)\n",
    "# end = time.time()\n",
    "# elapsed = end - start\n",
    "# #     print(\"Time to complete: \", elapsed, \"seconds\")\n",
    "\n",
    "# predictions = clf.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# print(\"Accuracy: \" , accuracy)\n",
    "# CM = confusion_matrix(y_test, predictions)\n",
    "# FP = CM.sum(axis=0) - np.diag(CM)  \n",
    "# FN = CM.sum(axis=1) - np.diag(CM)\n",
    "# TP = np.diag(CM)\n",
    "# TN = CM.sum() - (FP + FN + TP)\n",
    "# Sensitivity = TP/(TP+FN)\n",
    "# Specificity = TN/(TN+FP)\n",
    "# print(\"Sensitivity: \" , Sensitivity)\n",
    "\n",
    "# print(\"Specificity: \" , Specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
